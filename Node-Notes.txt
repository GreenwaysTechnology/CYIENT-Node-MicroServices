					Node.js
............................................................................................

What is Node.js?

  Node.js is platform and runtime for javascript lang.

Platform: collection of tools
Runtime: Execution engine where javascript can be executed..

Why Node.js?

History of Node.js:

Ryan Dahl who created Node.js.When he was doing phd in math, who got bored in math , so who
started working on different project by looking the project "flicker" , he was thinking how flicker uploades photos into server.

He attended conference "nginx" conference where who insipred "Non Blocking" Web Server.

He started thinking how to build nginx like server to build web application -  non blocking webservers.

He was thinking how to put java language, but java language was not ready for non blocking computing.Why cant use "javascript", javascript inside browser is non blocking language.

The same time, google published "open source javascript runtime" called v8.

Ryan thought using v8 we can build arch for building non blocking web servers.===>Node.js


-Blocking and Non Blocking:
...........................

File Descriptor:
................

-FD is a datastructure presented inside os kernal at very low level
-FD is mapper between os and hardware layer
-FD is entry and exit point of os.

.............................................................................................

Blocking IO Example: java:

import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;

public class CopyBytes {
    public static void main(String[] args) throws IOException {

        FileInputStream in = null;
        FileOutputStream out = null;

        try {
            in = new FileInputStream("xanadu.txt");
            out = new FileOutputStream("outagain.txt");
            int c;

            while ((c = in.read()) != -1) {
                out.write(c);
            }

	   //some other api call
	    myapi(); // will not be called until read operation and write operation is            completed

        } finally {
            if (in != null) {
                in.close();
            }
            if (out != null) {
                out.close();
            }
        }
    }
}
////////////////////////////////////////////////////////////////////////////////////////////

Blocking io means:

 Application process is waiting until data is read from the kernal.
 if data is availble inside application only, it will move the next cycle.
............................................................................................
				Multithreading and Networking
............................................................................................

Multi Threading and IO (Blocking IO):

In General application platforms(jvm,CLR)(process) is multi threaded.

WebServers and Web Containers for any technology(java,.net,python,php) are multi threaded.


Web Containers and Request handling:
...................................

Each Request is mapped with a single thread

Request Per Thread Model

100 request === 100 Threads

Eg:

1.client-1 asks 1 gb file from the web server

 client-----request-----|WebServer----create/use a thread --starts io operations
 client-----request-----|WebServer----create/use a thread --starts io operations
 client-----request-----|WebServer----create/use a thread --starts io operations
 client-----request-----|WebServer----create/use a thread --starts io operations
 client-----request-----|WebServer----create/use a thread --starts io operations
 client-----request-----|WebServer----create/use a thread --starts io operations


Threading Model:

 -  Each Request is assigned to thread

C10k : concurrently handling ten thousand connections

A web server should handle 10k connections at the same point of time(may be 1sc/1min)

C10k is one of the real time problem, expectation was if web server able to handle
10k connections, then it is good infra structure,so i dont need to add more machines.

How to reduce servers , how to utilize the existing hardware resouces.

               "The birth of non blocking technology" / How to reduce threads.


Problems of Multi Threaded Models:

1.Context Switch:
   - if a thread is assigned for a client request, that request takes more time to process.
 thread need to be paused.
    Moving a thread from sleep to running(active) --- active to sleep - ctx switch..

cpu takes much time on thread schduling, so it decreases the performance of the server.

2.memory
   Every thread eats upto 1MB of memory.

............................................................................................

Non Blocking io apis:

In 2000,Linux Operating system started providing, apis in order to perform non blocking io operation.

1.select

2.poll

Select vs poll.

3.epoll

What is epoll?

 Epoll is a program which monitors fd table.
 Fd table is array.
 epoll has a for loop which iterates fd table

 epollfd = epoll_create1(0);

infinit loop
 for(;;){
     read array(fd) entries from 0th index
     checks data availablity from the hardware
     if yes
	 copy data from the hardware to kernal buffer
     else
       move next index
      checks daa availablity from the hardware for 1st index.
    ....
    move until the last index.
   
 }


Steps:

1.thread starts  calling sys call for network io, while doing, it registers a handler function which will be used later by the thread.

2.thread gets control immediately since kernal relases the control

3.Thread starts processing other tasks

Kernal side

1. loop is running by watching fds

2. data is available

3. kernal copies data into buffer

4. kernal emits event

Application

4. Receive events process the event by assigning handler function.

5. Handler function gets called, send data to Caller(user).

.............................................................................................
				How node implements the nonblocking arch
..............................................................................................

Node.js:

-Multi platform(any os), non blocking ,event processing archiecture.
-Reduces more threads,having limited threads-single thread for event processing.
-Suitable for large network concurrency applications.

 1000 requests = 1 thread.
Node components:

V8:


libuv:
  libuv is a multi-platform support library with a focus on asynchronous I/O.
  libuv is collection of c apis for multiple operatings
    -libuv works with epoll in linux
    -libuv works with kqueue in mac/open bsd os
    -libuv works with iocp in windows

Features:

Full-featured event loop backed by epoll, kqueue, IOCP, event ports.
Asynchronous TCP and UDP sockets
Asynchronous DNS resolution
Asynchronous file and file system operations
File system events
ANSI escape code controlled TTY
IPC with socket sharing, using Unix domain sockets or named pipes (Windows)
Child processes
Thread pool
Signal handling
High resolution clock
Threading and synchronization primitives


libuv contains:

1. event loop thread:

  This is demaon thread, starts spinning for listening for incomming events from os kernal space.

2.Thread Pools
   libuv maintains set of threads other than event loop thread for doing "BLOCKING" IO operations.

Warining; 
   dont over use thread pools , because if use more threads from the thread poll then it impacts performance,memory...
   Dont block event loop thread.

////////////////////////////////////////////////////////////////////////////////////////////
                                NonBlocking and Async implementation
............................................................................................

In order to write non blocking  apps.

 -Language/Platform must provide high level apis
	 -Node provides lot of high level apis 
 -We need to provide listener function/callback function, for handling result

Listener function has two phases:

1.Function must be registered before calling kernal
   Registernation is based on event name.

2.Functions gets called by thread once the event is given

Every listener function is higher order function : Function as parameter.


How javascript /node understands that programs need proceed by event loops thread.
what are blocking api and what are non blocking api.

->All apis are generally blocking except apis which binds with non blocking apis.

eg:
 console.log() - blocking

Node provides non blocking category of apis

1.timers

2.General fs io apis

3.all network api
   http,tcp,udp


All non blockings are powered "handler/callback/listener" functions.

Listener functions are generally higher order function: Passed as parameter.


Non blocking coding Styles:

Note: All are same but just wrappers on top that.

1.callback style /listener

2.Promise style : wrapper for callbacks

3.async functions and await : wrapper for promise.


Common Non Blocking Apis provided by node

1.timers
2.file system apis
3.networking apis
etc....

1.timers

1.settimeout

//

function blockMe(message){
   console.log(message)
}
function delay(action) {
    //non blocking api
    setTimeout(action, 5000)
}

blockMe('starting')
delay(function () {
    console.log('i am delayed function!!!!')
})
blockMe('ending')

//arrow version.

const blockMe = message => console.log(message)

const delay = action => {
    //non blocking api
    setTimeout(action, 5000)
}

blockMe('starting')
delay(() => console.log('i am delayed function!!!!'))
blockMe('ending')


Use case : what if async function returns data.

const blockMe = message => console.log(message)

const delay = action => {
    //non blocking api
    let response = 'Data from server'
    setTimeout(action, 5000,response)
}

blockMe('starting')
delay(response => console.log(response))
blockMe('ending')
..............................................................................................
					Nested Callbacks
..............................................................................................

 The output of one callback, will be input to another callback.

Use case

 - call getUser api, which returns user if not , throw error.

 - Based on user i need to call login method, if login failed throw error

 - Based on login output, i need to call dashboard

//nested callbacks ; the output of one callback will be input to the another callback.

const getUser = (resolve, reject) => {
    console.log('Get User is called');
    //biz logic
    let user = { id: 1, name: 'admin', password: 'admin' }
    let error = { code: 404, message: 'User not found' }
    //user = null;
    if (user) {
        setTimeout(resolve, 1000, user);
    } else {
        setTimeout(reject, 1000, error);
    }
};

const login = (user, resolve, reject) => {
    console.log('login is called');

    //login logic
    let status = 'Login success';
    let error = { code: 404, message: 'Login failed' }
    if (user.name === 'admin' && user.password === 'admin') {
        setTimeout(resolve, 1000, status);
    }
    else {
        setTimeout(reject, 1000, error);
    }

}
const showPage = (status, resolve, reject) => {
    console.log('Show page is called');

    //login logic
    let adminPage = 'Admin Page';
    let guestPage = 'Guest Page'
    if (status === 'Login success') {
        setTimeout(resolve, 1000, adminPage);
    }
    else {
        setTimeout(reject, 1000, guestPage);
    }

}


getUser(user => {
    login(user, status => {
        showPage(status, page => {
            console.log(page);
        }, errorPage => {
            console.error(errorPage)
        })
    }, err => {
        console.error(err);
    });
}, err => {
    console.error(err);
});

The Problems of Nested Callbacks:
................................

Questions:

1.Whether this code is able to understand quickly
2.Whether this code is able to debug
3.Whehter this code is scalable?
4.whether this code is maintaiable?

fs.readdir(source, function (err, files) {
  if (err) {
    console.log('Error finding files: ' + err)
  } else {
    files.forEach(function (filename, fileIndex) {
      console.log(filename)
      gm(source + filename).size(function (err, values) {
        if (err) {
          console.log('Error identifying file size: ' + err)
        } else {
          console.log(filename + ' : ' + values)
          aspect = (values.width / values.height)
          widths.forEach(function (width, widthIndex) {
            height = Math.round(width / aspect)
            console.log('resizing ' + filename + 'to ' + height + 'x' + height)
            this.resize(width, height).write(dest + 'w' + width + '_' + filename, function(err) {
              if (err) console.log('Error writing file: ' + err)
            })
          }.bind(this))
        }
      })
    })
  }
})

"Callback Hell":
................

 -It is not bug or error in code
 -It is way of writing callback based program
 -Callback based non blocking programming hard to understand,maintain,debug,scale Which 
  called as "Callback Hell".

How to write better async/non blocking code without writings callbacks?

-Generally without callbacks not possible to write async/non blocking code.
-Rather we can abstract complexity of writting callbacks.

In 2005, JQUERY team started with working complex callback patterns, they found callback hell problem.

They proposed a  Design pattern to write better callback programming(Async) programming.

  "Promise".

Promise is design pattern which hides complexity of callback patterns


Since Promise is design pattern, many people have implemented Promise design pattern.

1.JQuery -first promise implementation
2.many libs and frameworks


...........................................................................................

In order standarize , ECMA committe decided to include Promise Design pattern at language level .(ES 6)
2012 E6 Commit introduced promise design pattern  as  "Promise" Object  in javascript.



Promises and non blocking,async and callback hell issues:
.........................................................

features of Promise Object:

1.Promise by deafult is Async. Which implements timer api with 0 ms .

Promise can be used with any async callback based  implementations.


Objective:

 To remove callbacks in async/non blocking code. write cleaner async programming.
 To remove complex callback chaining code.

Promise Implemenation:How to create Promise Object

1. Create Promise Object from Promise contructor -  new Promise()
2. Create Promise object from factory apis       - Promise.resolve(), Promise.reject()

Promise object methods:
1.then - success
2.catch - errors
3.finally - clean up
factory api to create Promise object
4.resolve
5.reject
.......................................
6.all
7.race

Promise with factory pattern: success usecase

//callback based
// const delay = action => {
//     setTimeout(action, 0)
// }
// delay(res=>console.log(res))

const blockMe = message => console.log(message)
const delay = () => {
    return Promise.resolve('Hello');
}

blockMe('starting')
delay().then(res => console.log(res))
blockMe('ending')

Promise with factory pattern : Error Use case

const blockMe = message => console.log(message)
const delay = () => {
    return Promise.reject('somethingwent wrong');
}

blockMe('starting')
delay()
.then(res => console.log(res))
.catch(err=>console.log(err))
blockMe('ending')

Promise with factory pattern: resolve and reject


const blockMe = message => console.log(message)
const login = (username, password) => {
    if (username === 'admin' && password === 'admin') {
        return Promise.resolve('login success')
    } else {
        return Promise.reject('Login Failed')
    }
}

blockMe('starting')
login('admin', 'admin')
    .then(res => console.log(res))
    .catch(err => console.log(err));
login('foo', 'bar')
    .then(res => console.log(res))
    .catch(err => console.log(err));
blockMe('ending')
............................................................................................

How to convert existing callback based non blocking code into Promise Powered?

 Using Promise Constructor pattern.

//callback code
const login = (username, password, resolve, reject) => {
    if (username === 'admin' && password === 'admin') {
        setTimeout(resolve, 1000, 'login success')
    } else {
        setTimeout(reject, 1000, 'login failed')

    }
}
login('admin', 'admin', status => console.log(status), error => console.log(error))

const auth = (username, password) => {
    return new Promise((resolve, reject) => {
        if (username === 'admin' && password === 'admin') {
            setTimeout(resolve, 2000, 'login success-Promise')
        } else {
            setTimeout(reject, 2000, 'login failed-Promise')
        }
    });
}
auth('admin', 'admin')
    .then(res => console.log(res))
    .catch(err => console.log(err));
/////////////////////////////////////////////////////////////////////////////////////////////

Callback Hell and Promises : How to solve Callback Issues?

const getUser = () => {
    console.log('Get User is called');
    //biz logic
    return new Promise((resolve, reject) => {
        let user = { id: 1, name: 'admin', password: 'admin' }
        let error = { code: 404, message: 'User not found' }
        //user = null;
        if (user) {
            setTimeout(resolve, 1000, user);
        } else {
            setTimeout(reject, 1000, error);
        }
    })
};

const login = user => {
    console.log('login is called');
    return new Promise((resolve, reject) => {
        //login logic
        let status = 'Login success';
        let error = { code: 404, message: 'Login failed' }
        if (user.name === 'admin' && user.password === 'admin') {
            setTimeout(resolve, 1000, status);
        }
        else {
            setTimeout(reject, 1000, error);
        }
    })

}
const showPage = status => {
    console.log('Show page is called');
    return new Promise((resolve, reject) => {
        //login logic
        let adminPage = 'Admin Page';
        let guestPage = 'Guest Page'
        if (status === 'Login success') {
            setTimeout(resolve, 1000, adminPage);
        }
        else {
            setTimeout(reject, 1000, guestPage);
        }
    });

}


// getUser(user => {
//     login(user, status => {
//         showPage(status, page => {
//             console.log(page);
//         }, errorPage => {
//             console.error(errorPage)
//         })
//     }, err => {
//         console.error(err);
//     });
// }, err => {
//     console.error(err);
// });

getUser()
    .then(user => {
        login(user)
            .then(status => {
                showPage(status)
                    .then(page => {
                        console.log(page)
                    })
                    .catch(err => {
                        console.log(err);
                    })
            })
            .catch(err => console.log(err))
    })
    .catch(err => console.log(err));
//////
getUser()
    .then(user => {
        return login(user) //return Promise
    })
    .then(status => {
        return showPage(status)//return Promise
    })
    .then(page => console.log(page))
    .catch(err => console.log(err));

/////
getUser()
    .then(user => login(user))
    .then(status => showPage(status))
    .then(page => console.log(page))
    .catch(err => console.log(err));

//Using destrucing syntax: method reference
const { log } = console;;
getUser()
    .then(login)
    .then(showPage)
    .then(log)
    .catch(log);

.............................................................................................
If code grows with many promises, you can see more "thenables",Which leads the problem called
"Promise Hell".

Promise Hell:

 In large code base, you can see many "thenables", how to reduce thenables.

ES 7 introduced even simple keywords , looks like sync program/sequencial call.
"Sync style of async programm"

"async function and await keyword".


const { log } = console;;
getUser()
    .then(login)
    .then(showPage)
    .then(log)
    .catch(log);

The above code can be reduced.

const getUser = () => {
    console.log('Get User is called');
    //biz logic
    return new Promise((resolve, reject) => {
        let user = { id: 1, name: 'admin', password: 'admin' }
        let error = { code: 404, message: 'User not found' }
        //user = null;
        if (user) {
            setTimeout(resolve, 1000, user);
        } else {
            setTimeout(reject, 1000, error);
        }
    })
};

const login = user => {
    console.log('login is called');
    return new Promise((resolve, reject) => {
        //login logic
        let status = 'Login success';
        let error = { code: 404, message: 'Login failed' }
        if (user.name === 'admin' && user.password === 'admin') {
            setTimeout(resolve, 1000, status);
        }
        else {
            setTimeout(reject, 1000, error);
        }
    })

}
const showPage = status => {
    console.log('Show page is called');
    return new Promise((resolve, reject) => {
        //login logic
        let adminPage = 'Admin Page';
        let guestPage = 'Guest Page'
        if (status === 'Login success') {
            setTimeout(resolve, 1000, adminPage);
        }
        else {
            setTimeout(reject, 1000, guestPage);
        }
    });

}

// const { log } = console;;
// getUser()
//     .then(login)
//     .then(showPage)
//     .then(log)
//     .catch(log);

async function main() {

    try {
        const user = await getUser();
        const status = await login(user);
        const page = await showPage(status);
        console.log(user, status, page);
    }
    catch (err) {
        console.log(err);
    }

}
main()

Promise Chaning:Nested Promises:

 The output of one promise , will be input to the another promise.

Promise Composition:

 The Calling many async/non blocking apis, parreally, all results will be settled 
once all promise/non blocking apis are completed.

resolves when every input Promise has resolved or
rejected when any of the input Promise has rejected.


function getValue1() {

    //return Promise.resolve(1)
    return new Promise((resolve, reject) => {
        setTimeout(resolve, 10000, 1);
    })
}
function getValue2() {
    return new Promise((resolve, reject) => {
        setTimeout(resolve, 15000, 2);
    })
}
function getValue3() {
    return Promise.resolve(3)
}
function getValue4() {
    // return new Promise((resolve, reject) => {
    //     setTimeout(reject, 6000, "error");
    // })
    return Promise.resolve(4)

}

// Promise.all([getValue1(), getValue2(), getValue3(),getValue4()])
//     .then(res => {
//         console.log(res)
//     })
//     .catch(err => {
//         console.log(err);
//     });

async function main() {

    try {
        const res = await Promise.all([getValue1(), getValue2(), getValue3(), getValue4()])
        console.log(res);
    }
    catch (err) {
        console.log(err);
    }
}
main();

Promise.race() vs. Promise.all()

The Promise.all() returns a promise that resolves to an array of values from the input promises while the Promise.race() returns a promise that resolves to the value from the first settled promise.

.............................................................................................
					Modularity:
.............................................................................................

What is Modularity?
  Breaking application into smaller units.

Types of Modularity?

1.Physicall modularity
  
  folders,files :  code is kept/organized into files and folders

2.Logical modularity
  code is kept into classes,functions,objects

Java:

 folders/files
  com/ibm/util/Utility.java

 package com.ibm.util

 class Utility{

 }



What about javascript Modularity?

1.Physicall modularity
   fodlers/file based
   scripts/index.js
2.logical modularity
  js does not offer logical modularity at language level.

Once js started growing in large scale, dev struck to organize code.

2000, Smart developers started thinking about how to modualrize js code.

Module design patterns came.

1.Namespace design pattern : 2000 : jquery
2.AMD -Async Module Defintion : dojo
---------------------------------------------------------
3.CJS - Common JS =  namespace + amd -2005
4.ES 6 Module design pattern  = amd + cjs - 2012 ECMA Committe introduced this pattern
------------------------------------------------------------
5.System = AMD = CJS + ES 6
6.UMD = NAMESPACE + AMD + CJS = ES 6


only two design patterns are used in development

1.CJS - Common JS =  namespace + amd
2.ES 6 Module design pattern  = amd + cjs

CJS ; implemented inside node js. node supports commonjs by default.

I can organize the code , based on these patterns, but what about runtimes?

  js runtime never suppport these patterns directly 
  each design pattern is lib.

 Loaders : it is simple js lib to help link and load js files.

Node.js has built in cjs loader and linker, so we dont need to install loaders
Browers has no built in support for any modular design pattern natively except , namespace.

////////////////////////////////////////////////////////////////////////////////////////////

				COMMONJS - Nodejs
////////////////////////////////////////////////////////////////////////////////////////////

Two important task in modules:

1.how to link files

  We need loaders and linkers - node.js provides by default
eg
java : import 

cjs : require('fileNametoBelinked')

Use case 1 : how to link files 

src/mylib.js
console.log('mylib')

src/index.js
const res = require('./mylib')

$node src/index.js
mylib

2.how to share code

What is code , What code can be shared to other files.

code : collection of variables,functions,classes,objects,arrays.

Ways of code sharing:

1.Pack the code into one object(literal) which you want to share



-exports
   -used to share code in form of object
   -code is packed inside object and shared that object
-module.exports
   -used to share code as it is.

mycode.js
/**
 * function require(fileName){
 * //exports is variable, its value is plain literal object.
 *  let exports = {}   
 *  *  exports.firstName = ''
 * 
 *   return exports
 * }
 */

exports.firstName = 'Subramanian'
exports.lastName = 'Murugan'
exports.age = 41
exports.isValid = true
exports.skills = ['node','microservices','java']
exports.calculate = function(){
    return 100
}

index.js
// const res = require('./mycode')
// console.log(res)
// console.log(res.firstName)

const {firstName,lastName,skills,calculate} = require('./mycode')

console.log(firstName,lastName,skills,calculate())


-module.exports
   -used to share code as it is.


Export class and later you create object for that class

Greeter.js

class Greeter {
    constructor() {

    }
    sayHello(name) {
        return `Hello ${name}`
    }
}

//send a class 
module.exports = Greeter;


index.js
// const test = require('./Greeter');
// let greetMe = new test();
// console.log(greetMe.sayHello('subramanian'))

const Greeter = require('./Greeter')
let greetMe = new Greeter();
console.log(greetMe.sayHello('subramanian'))


Export Object and later you can use object

HelloService.js

class HelloService {
    constructor() {

    }
    sayHello(name) {
        return `Hello ${name}`
    }
}
module.exports = new HelloService();

index.js
// const helloService = require('./HelloService')
const { sayHello } = require('./HelloService')

console.log(sayHello('Subramanian'))
..............................................................................................

folders and file structures:
.............................

Objective:
 Build api

src
 |
 services
 mock-data
 app.js


services/todo.service.js
const TODOS = require('../mock-data/todo')

class TodoService {
    //api:async
    findAll() {
        return new Promise((resolve, reject) => {
            setTimeout(resolve, 1000, TODOS)
        });
    }
    //add apis
    save(todo) {

    }
    findByid(id) {

    }
    fetchCompletedTodos() {

    }
    remove(id){

    }
    update(id){
        
    }
}
module.exports = new TodoService();

src/mock-data/todo.js
note: https://jsonplaceholder.typicode.com/todos
go to this link and copy all data and paste into your code

module.exports = [
    {
        userId: 1,
        id: 1,
        title: "delectus aut autem",
        completed: false
    }]

src/app.js
const { findAll } = require('./services/Todo.service');

async function main() {
    try {
        const todos =  await findAll();
        console.log(todos)
    }
    catch (err) {
        console.log(err);
    }
}
main();
//////////////////////////////////////////////////////////////////////////////////////////////						Node.js api modules
..............................................................................................


Types of modules:

1.Custom modules
  built by us
2.Built in modules
   provided by node.js  
3.Third party modules-Provided by third party/community
  libs,frameworks -eg React,angular,Vue,express,jquery..............
..............................................................................................
Node js Built in modules:
..........................

File System io

Networking

etc...

1.os 

The os module provides operating system-related utility methods and properties. It can be accessed using:

const {arch,cpus ,version} = require('os');

console.log(arch())
console.log(cpus())
console.log(version())


./ vs ''
.........

 require('./services/TODOService');
  ->here you can see ./
  ./ -current dir

 require('os'); => 
  -here no ./ 

Why?

Note : if you are java devp, you know the classpath , how it works?


require('os');

Node internally uses a search algorthim,node always looks the folder called
 "node_modules" in the current project, if not , then it searches, the node in built 
installtion folder---c:/pf/node/node_modules--if it finds it will pick up from there else it will throw error.

require('./services/TODOService');
   it will lookup in the current dir or sub dirs only.

nternal/modules/cjs/loader.js:800
    throw err;
    ^

Error: Cannot find module 'osxx'
Require stack:
- C:\session\ibm\feb\nodems\mynodeapps\src\index.js
[90m    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:797:15)[39m
[90m    at Function.Module._load (internal/modules/cjs/loader.js:690:27)[39m
[90m    at Module.require (internal/modules/cjs/loader.js:852:19)[39m
[90m    at require (internal/modules/cjs/helpers.js:74:18)[39m
    at Object.<anonymous> (C:\session\ibm\feb\nodems\mynodeapps\src\index.js:1:32)
[90m    at Module._compile (internal/modules/cjs/loader.js:959:30)[39m
[90m    at Object.Module._extensions..js (internal/modules/cjs/loader.js:995:10)[39m
[90m    at Module.load (internal/modules/cjs/loader.js:815:32)[39m
[90m    at Function.Module._load (internal/modules/cjs/loader.js:727:14)[39m
[90m    at Function.Module.runMain (internal/modules/cjs/loader.js:1047:10)[39m {
  code: [32m'MODULE_NOT_FOUND'[39m,
  requireStack: [ [32m'C:\\session\\ibm\\feb\\nodems\\mynodeapps\\src\\index.js'[39m ]
}
//////////////////////////////////////////////////////////////////////////////////////////
				Event Emitter
..........................................................................................

Node is Event Driven Platform. Node programs works based on events.

Generally events are published by os kernal, event loop thread process those events.

Types of Events:

1.Kernal Events - Timer,IO Events
2.Application Events -  events published and consumed by application itself.

Application Events:
...................

Event Emitter Module: events

   Much of the Node.js core API is built around an idiomatic asynchronous event-driven architecture in which certain kinds of objects (called "emitters") emit named events that cause Function objects ("listeners") to be called.

Roles:

1.Emitter 
    Emitter emits events
2.Listener
    Listener listens

Use case : we create object who acts listener and emitter.

const EventEmitter = require('events');

class CustomerService extends EventEmitter {
    constructor() {
        super();
        //register custom events
        this.on('sales', data => { console.log(data) });
    }
    //biz
    buy(product) {
        this.emit('sales', product) //emit event and send data
    }
}
let customerService = new CustomerService();
customerService.buy({ id: 1, name: 'Node.js In Action', category: 'book', price: 100 })
customerService.buy({ id: 2, name: 'libuv.js In Action', category: 'book', price: 100 })
...........................................................................................
					IO
				   (File System IO) :Hard disk
............................................................................................
Node was built for performning non blocking io / async io.

What if i want to write blocking io is it Possible?

 Yes!

Node supports FS blocking io operations.

File System:fs

-used to read , write into and from disk.

mode :

  - sync /blocking 
  - async/ non blocking

based on data read/write:

 -non streaming
 -streaming

const fs = require('fs');
//read,write, all fs operations.

const filePath = './src/assets/info.txt';
const options = {
    encoding: 'UTF-8'
}
function block(message){
    console.log(message)
}
block('start')
fs.readFile(filePath, options, (err, data) => {
    if (err) throw err;
    console.log(data);
})
block('end')
..............................................................................................

Blocking IO Operations: 

-Node allows blocking io operations
-Blocking io will block the current event loop thread.
-In order to optimize , the event loop thread does not perform real io calls,Node provides
 a separate thread  called "Worker pool thread" 

const fs = require('fs')

function block(message) {
    console.log(message)
}

const filePath = './src/assets/info.txt';
const options = {
    encoding: 'UTF-8'
}
block('start')
const data = fs.readFileSync(filePath, options)
console.log(data)
block('end')
/////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////

How to write data into file async:

const fs = require('fs');

const filePath = './src/assets/infowrite.txt';
const options = {
    encoding: 'utf-8'
}
const data = 'Hello,How are you';

fs.writeFile(filePath, data, options, err => {
  if (err) throw err;
  console.log(`data has been written into ${filePath}`)
})
////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////

How to write data into file async:

const fs = require('fs');

const filePath = './src/assets/infowrite.txt';
const options = {
    encoding: 'utf-8'
}
const data = 'Hello,How are you';

fs.writeFile(filePath, data, options, err => {
  if (err) throw err;
  console.log(`data has been written into ${filePath}`)
})
////////////////////////////////////////////////////////////////////////////////////////////
How to avoid file path hardcoding?

path module:

The path module provides utilities for working with file and directory paths. It can be accessed using:


Node Global Variables:
......................

 Are variables or constants available inside node process , which is not part of any module.

-node provides lot of global variables

__dirname  : current directory name
C:\session\ibm\2021\june\nodemicroservices\nodeapps\src

__filename :current directory name + fileName
C:\session\ibm\2021\june\nodemicroservices\nodeapps\src\index.js

const fs = require('fs');
const path = require('path');

// console.log(__dirname)
// console.log(__filename)
// const filePath = './src/assets/infowrite.txt';
const filePath = path.join(__dirname,'assets/infowrite.txt')
const options = {
    encoding: 'utf-8'
}
const data = 'Hello,How are you';

fs.writeFile(filePath, data, options, err => {
  if (err) throw err;
  console.log(`data has been written into ${filePath}`)
})
..............................................................................................
				Callback FS api into Promises
..............................................................................................

Node provides callback style apis by default. if i want to convert into promise.

const { readFile } = require('./services/FileService')
const path = require('path');


async function main() {
   
    try {
        const filePath = path.join(__dirname, 'assets/info.txt')
        const options = {
            encoding: 'utf-8'
        }
        const data = await readFile(filePath, options)
        console.log(data);
    }
    catch (err) {
        console.log(err);
    }
}
main()

...............................................................................................
const fs = require('fs');

class FileService {
    constructor() {

    }
    readFile(filePath, options) {
        return new Promise((resolve, reject) => {
            fs.readFile(filePath, options, (err, data) => {
                if (err) {
                    reject(err)
                } else {
                    resolve(data);
                }
            })
        })
    }
}
module.exports = new FileService();
..............................................................................................
				Event driven IO : Streaming
..............................................................................................


if you want to read or write from file or socket , you can do in two ways

1.Non streaming:
   only file io is supported, network io not supported

-once file is read, the entire is loaded into node process buffer(memory), then it will be delivered to caller.

-if more files are loaded into node process, node process gets crashed.

-non streaming mode is not suitable for large and big files read or write operation.

fs.readFile() and fs.writeFile are non streaming apis.

2.streaming:
   supported by fs and also network apis



-Streaming is nothing but flow of data(chunks).
-Streaming allows move the data from one place to another place one by one.
-Streaming apis are other wise called evented io. which is powered events.


Types of Streams:

1.Readable Stream : input
2.Writeable stream : output
3.Duplex stream : read + write

Node has lot of built in stream apis
....................................

Built in readable Streams:

-HTTP responses, on the client
-HTTP requests, on the server
-fs read streams
-zlib streams
-crypto streams
-TCP sockets
-child process stdout and stderr
-process.stdin

Writable Streams:

-HTTP requests, on the client
-HTTP responses, on the server
-fs write streams
-zlib streams
-crypto streams
-TCP sockets
-child process stdin
-process.stdout, process.stderr


All streaming apis are powered with events
node io streams has built in events.
events are emitted by node.
Our programs are listeners

Common events in all io
.........................


1.data event:
 which is emitted by node, for each chunk.

2.close event:
  The 'close' event is emitted when the stream and any of its underlying resources (a file descriptor, for example) have been closed.

3.end event:
 The 'end' event is emitted when there is no more data to be consumed from the stream.

3.Event: 'error'
 The 'error' event may be emitted by a Readable implementation at any time
Typically, this may occur if the underlying stream is unable to generate data due to an underlying internal failure, or when a stream implementation attempts to push an invalid chunk of data.


const fs = require('fs');
const path = require('path');
const { log } = console;

const fileName = path.join(__dirname, 'assets/info.txt');
const config = {
    encoding: 'UTF-8'
}

const inputStream = fs.createReadStream(fileName, config);

//attach event listeners

//data event is emitted by os for each chunk of data
let data = ''
inputStream.on('data', chunk=> {
    log(`Received ${chunk.length} bytes of data.`)
    data += chunk;
})

//end event is called , no more chunk of data is availble.
inputStream.on('end', () => {
    log('There will be no more data to read!');
    log(data);
})

//error event: for error handling
inputStream.on('error', err => {
    log(`Some thing went wrong! ${err}`)
});

...........................................................................................

Write Stream:
............

const fs = require('fs');
const path = require('path');

const fileName = path.join(__dirname, 'assets/grains.txt');

const config = {
    encoding: 'utf8',
    flag: 'w'
};
const outputStream = fs.createWriteStream(fileName, config);

const grains = ['wheat', 'rice', 'oats'];

grains.forEach(grain => {
    outputStream.write(grain + " ");
    console.log("Wrote: %s", grain);
});

outputStream.close();

outputStream.on('close', function () {
    console.log('file has been closed ')
})
............................................................................................

Testing data events with big files

BigFile write:
const fs = require('fs');
const path = require('path')

const filePath = path.join(__dirname, "assets/big.file")
const file = fs.createWriteStream(filePath);

for (let i = 0; i <= 1e6; i++) {
    file.write('Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n');
}

file.end();
............................................................................................

const fs = require('fs');
const path = require('path');
const { log } = console;

const fileName = path.join(__dirname, 'assets/big.file');
const config = {
    encoding: 'UTF-8'
}
const inputStream = fs.createReadStream(fileName, config);

//data event is emitted by os for each chunk of data
let data = ''
inputStream.on('data', chunk=> {
    log(`Received ${chunk.length} bytes of data.`)
    data += chunk;
})

//end event is called , no more chunk of data is availble.
inputStream.on('end', () => {
    log('There will be no more data to read!');
    //log(data);
})

//error event: for error handling
inputStream.on('error', err => {
    log(`Some thing went wrong! ${err}`)
});
..............................................................................................

Read + Write:
.............
const fs = require('fs');
const path = require('path');

//read
const inputfileName = path.join(__dirname, 'assets/big.file');
//write
const outputFileName = path.join(__dirname, 'assets/bigcopy.file');

const config = {
    encoding: 'UTF-8'
}

const inputStream = fs.createReadStream(inputfileName, config);
const outputStream = fs.createWriteStream(outputFileName, config);

//Register data event.
inputStream.on('data', function (chunk) {
    console.log(`Received ${chunk.length} bytes of data.`);
    outputStream.write(chunk);
});


//end event
inputStream.on('end', function () {
    console.log('There will be no more data to read!');
    outputStream.close();
})

//error event: for error handling
inputStream.on('error', function (err) {
    console.log(`Some thing went wrong! ${err}`)
});

outputStream.on('close', function () {
    console.log(`File write operation is completed`);
});
/////////////////////////////////////////////////////////////////////////////////////////////
				BackPressure
.............................................................................................


Backpressure:
Problems when you do read and write together

1. In general read operation is faster than write operation


Back Pressure means inputstream is fast, outputstream slow, then data will be
lost.


How to handle back pressure?

 apis  : pause,resume,drain event

pause : to close the upstream, not to emit data
resume : to open the open upstream , to emit data

drain event: if drain event is called.

const fs = require('fs');
const path = require('path');

const inputfileName = path.join(__dirname, 'assets/big.file');
const outputfileName = path.join(__dirname, 'assets/bigcopy.file');

const config = {
    encoding: 'UTF-8'
}

//Back pressure handling
const readerStream = fs.createReadStream(inputfileName, config);
const writeStr = fs.createWriteStream(outputfileName, config);



readerStream.on('data', function (chunk) {
    console.log(`Received ${chunk.length} bytes of data.`);
    let buffer_good = writeStr.write(chunk);
    if (!buffer_good) readerStream.pause();
});
writeStr.on('drain', function () {
    console.log('buffer drained!');
    readerStream.resume();
});
readerStream.on('end', function () {
    //console.log(data);
});

readerStream.on('error', function (err) {
    console.log(err.stack);
});
...............................................................................................
pipe Method:

//pipe method is simplest method for implementing back pressure:


const fs = require('fs');
const path = require('path');

const inputfileName = path.join(__dirname, 'assets/big.file');
//write
const outputFileName = path.join(__dirname, 'assets/bigcopy.file');

const config = {
      encoding: 'UTF-8'
}

//Back pressure handling
const readerStream = fs.createReadStream(inputfileName, config);
const writeStr = fs.createWriteStream(outputFileName, config);

//backPressure streams
//pipe method is simplest method which wraps resume,pasuse,drain 
readerStream.pipe(writeStr);
..............................................................................................
			        HTTP Programming
.............................................................................................

How to build non blocking webservers and webapps?

You can create webservers and on which you can deploy apps, unlike traditional webserver model
where webserver is separate, and app is different.

Node invented for building network io applications.

Network implementation in non blocking:

HTTP module is used to build http server,app, deployment


HTTP modules objects:


1.Server
  Server object is used to implement http servers/web containers
2.ServerResponse
  Object is used to send data 
3.ClientRequest
   Request object is used to handle http client requests
4.IncommingMessage
   Represents message payloads.


Note: all http implemnetation is streaming powered by default.

Steps:

1.create Server.
2.request-response handling
3.starting server



const http = require('http');

const port = 3000;

const server=http.createServer((req,res)=>{
    //send response
    res.write('Hello Node')
    //close the stream
    res.end();
    //resonse events
    res.on('close',()=>{
        console.log('response closed')
    })
    res.on('finish',()=>{
        console.log('response finshed')
    })
})

//this event will be fired when a request recived to server
server.on('request',(req,res)=>{
    console.log(`Server received Request on ${new Date()}`)
})

//start server
server.listen(port,()=>{
    console.log(`HTTP server starts @ ${port}`)
});
//////////////////////////////////////////////////////////////////////////////////////////////

JSON:

const http = require('http');
const TODOS = require('./mock-data/todo');

const port = 3000;

const server=http.createServer((req,res)=>{

    //send response
    const todosJson = JSON.stringify(TODOS);

    //response headers
    res.writeHead(200, {
        'Content-Type': 'application/json',
        'customheader' : 'customerheadervalue'
    })

    res.write(todosJson)
    //close the stream
    res.end();
    //resonse events
    res.on('close',()=>{
        console.log('response closed')
    })
    res.on('finish',()=>{
        console.log('response finshed')
    })
})

//this event will be fired when a request recived to server
server.on('request',(req,res)=>{
    console.log(`Server received Request on ${new Date()}`)
})

//start server
server.listen(port,()=>{
    console.log(`HTTP server starts @ ${port}`)
});

.............................................................................................


const http = require('http');
const { findAll } = require('./services/Todo.service')

const port = 3000;

const server = http.createServer(async (req, res) => {
    //send response
    //response headers
    res.writeHead(200, {
        'Content-Type': 'application/json',
        'customheader': 'customerheadervalue'
    })

  // findAll(todos => {
    //     res.write(todos)
    //     res.end();
    // }, error => {
    //     res.write(error)
    //     res.end()
    // });
    // findAll()
    //     .then(todos => {
    //         res.write(todos)
    //         res.end();
    //     })
    //     .catch(error => {
    //         res.write(error)
    //         res.end()
    //     })

    try {
        const TODOS = await findAll();
        res.write(JSON.stringify(TODOS))
        //close the stream
        res.end();
    }
    catch (err) {
        res.write({ code: 404, message: 'Todo not found' })
        res.end();
    }
    //resonse events
    res.on('close', () => {
        console.log('response closed')
    })
    res.on('finish', () => {
        console.log('response finshed')
    })
})

//this event will be fired when a request recived to server
server.on('request', (req, res) => {
    console.log(`Server received Request on ${new Date()}`)
})

//start server
server.listen(port, () => {
    console.log(`HTTP server starts @ ${port}`)
});
.............................................................................................
				INPUT from the Client
.............................................................................................

Request Events:
...............
data -

const http = require('http');
const { log } = console;

const port = 3000;

const server = http.createServer((req, res) => {

    let body = '';
    //attach data event on request object
    req.on('data', chunk => {
        body += chunk;
        log(body);
    });

    res.end("Hello,Node")
    //attach close event on response event
    res.on('close', () => {
        log('response close event is called')
    });
    res.on('finish', () => {
        log('response has been sent /committed')
    });
});

server.listen(port, () => {
    console.log(`Http Server listens @ ${port}`)
});

server.on('request', (req, res) => {
    log(`request is recieved on ${port} -method is ${req.method} url ${req.url}`)
})
..............................................................................................
				  NPM - Node Package Manger
..............................................................................................


npm is tool is used to distribute node modules to others
and you can get node modules from other others.

npm tool is distributed along with node installation

npm uses public repository server called npmjs.com npmjs.org

tools and libs,frameworks all are distributed as node modules into repository.
..............................................................................................
				Javascript Apps


Javascripts apps could be server-side apps like web apps,webservices,microservices, client side apps angular,react,vue, mobile apps ......

There is common structure which is defined by npm.

The Project will have 

1.package.json file
   meta file which describes the project information
2.node_modules folder
  which contains libs/frameworks/tools code.

From where we can get libs/frameworks code?
  We have repository npmjs.com

create package.json file

>npm init

{
  "name": "nodeapps",
  "version": "1.0.0",
  "description": "This is node and npm project",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC"
}
package Types:

1.public package
  react
2.private package 
  @angular - @-npm private 


npm is used

to install,uninstall,publish node modules from node repo / into node repo.

if you install third party modules , into your project, node distributes npm tool ,using this you can install,uninstall,upgrade node modules.
.............................................................................................

























